\chapter{Model Inference and Revision}\label{chap:modelInference}
\begin{mybox}
In the previous chapter, we introduced several approaches of refined reachability analysis, which are more suitable for practical use (more efficient and more conclusive).
Nevertheless, these approaches can never take effect no matter how powerful they are, if the original model does not reflect the reality.

To model a biological computational system, one may consider two possible aspects: a first-step model built by biologists (variables, some confirmed transitions, some \textit{a priori} properties etc.) and the observations from experiments (time-series data, steady states, oscillations, etc.).

This chapter is dedicated to the introduction of three different approaches of model inference/revision:

\begin{itemize}
    \item \textit{via} reachability properties and candidate regulations
    \item \textit{via} partial correlation (statistics)
    \item \textit{via} reachability properties and time-series data
\end{itemize}

There lies very little nuance between model inference and model revision: these two operations begin with some \textit{a priori} information and/or observations, aiming at constructing a new model/modifying an existed model.
As a result, they take the information apart from the existing transitions into account, using different tools to transform this information into possible transitions in the model (also can modify or deny existing transitions).

\end{mybox}

\section{Background}
Model inference/learning can be useful not only in biology \cite{ribeiro2015learning} but also in other domains with the need of abstraction, e.g. robotics \cite{nguyen2011model}, multi-agent systems \cite{foerster2016learning}.
In the community of bioinformatics, DREAM  challenge\footnote{\url{http://dreamchallenges.org/about-dream}} is a well-known organization calling for the participation of the whole world on the newest bio-medical problems (called challenges). 
Among these challenges, some of them are in the domain of inference and prediction:
DREAM2\footnote{\url{https://www.synapse.org/\#!Synapse:syn2825374/wiki/71143}},
DREAM4\footnote{\url{https://www.synapse.org/\#!Synapse:syn2825304/wiki/71129}},
DREAM8\footnote{\url{https://www.synapse.org/\#!Synapse:syn1720047/wiki/55342}},
DREAM11\footnote{\url{https://www.synapse.org/\#!Synapse:syn6131484/wiki/402026}}.

Like in biology, the modeling structures in robotics are usually complex and with big scale, which is difficult in control, prediction and simulation.
Constructing an abstracted (often approximated) model is a compromising way of dealing with the mechanical and computational complexity.
However, the abstracted models are theoretically non-equivalent to the original ones because they contain different amount of information.
Even though there always lies an non-equivalence, we wish that the abstracted models are in bisimulation with the original systems with respect to certain variables and keep the same important properties as original systems.

Concretely speaking, we developed three approaches which are to be presented in this chapter:

\begin{enumerate}
    \item Constructing models from incomplete model and candidate regulations plus dynamic constraints
    \item Inferring models from continuous observation data
    \item Least revising existing models via \textit{a priori} knowledge (mainly reachability information)
\end{enumerate}

Among these three approaches, intuitively approach 1 has the least complexity. 
Because the most naive method, \textit{i.e.} brute force search is to verify every combination of the candidates if it satisfies the constraints. 
The models to be verified are of $O(2^n)$, where $n$ is the number of candidate transitions.
For approach 2, to obtain a transition $A\to a_i$ with $a_i$ fixed, there are at most $m-1$ possibilities for $A$ having one local state, $C_{m-1}^2$ possibilities for $A$ having 2 local states \ldots where $m$ is the number of variables.
Similarly, approach 3 also has a factorial complexity.

\section{Model Inference \textit{via} Candidate Regulations}\label{sec:modelInference}
We begin with the problem which seems to have the smallest complexity.
The brute force search that we just presented is still meaningless in real application.
Roughly speaking, we aim at finding the transitions among the candidates which meet the unsatisfied constraints and keep already satisfied constraints unchanged.

\subsection{Problem Description}
Briefly speaking, completion problem is:

incomplete model + candidate regulations + constraints $\to$ new model

The complete model contains all the elements in the incomplete model and consistent with all the \textit{a priori} information. 

\begin{definition}[Model completion in ABAN semantics]
    Given an incomplete ABAN $AB=(\Sigma, L, T)$ (where $T$ can be empty), a complete model is an ABAN $AB'=(\Sigma, L, T')$ which satisfies $T'\supseteq T$, $AB'$ consistent with the set of reachability constraints $C$ and the completion set $CS=T'\setminus T$ is consistent with the set of candidate regulations $R$, where
    \begin{itemize}
        \item $R=\{(body,head,sgn)\mid body\in \Sigma,\ head\in \Sigma,\ sgn\in \{0,1\}\}$ 
        \item $C=\{(\alpha,\omega,r)\mid\alpha \in L,\ \omega\in LS,\ r\in \{\mathbf{True,False}\}\}$
    \end{itemize}
\end{definition}

$R$ is the set of possible relations between variables, $body$ may inhibit (0) or promote (1) $head$.
$C$ is the set of \textit{a priori} reachability properties, $\omega$ is (un)reachable from $\alpha$.
The definition of consistency is straightforward, but its meaning changes for reachability constraints and candidate regulations.

\begin{definition}[Consistency]
\leavevmode
\makeatletter
\@nobreaktrue
\makeatother
\begin{itemize}
    \item An ABAN $AB$ is said consistent with a with the set of reachability constraints $C$ iff $\forall (\alpha,\omega,r)\in C$ s.t. $reach(\alpha,\omega)=r$
    \item A completion set $CS$ is said consistent with a with the set of candidate regulations $R$ if $\forall \acm{a_i}{b_{1-j}}{b_j}\in CS, \exists (body,head,sgn)\in R$ s.t. $body=a,\ head=b,\ (i=j)=sgn$. 
\end{itemize}
    
\end{definition}
Theoretically, to obtain a good new ABAN, we have to assure $T$ has no \textit{bad} transitions, because the completion operation is not able to remove or modify existing transitions. 

Before our research began, Paulev\'e \textit{et al.} had worked on cut-sets for reachability in large scale automata networks \cite{PAK13-CAV}, which is the reverse operation of completion sets.
Cut set is used to eliminate certain transitions according to unreachability properties.
By combining these two operations, one can construct/revise a model according to \textit{a priori} information (candidate regulations) and constraints (reachability).

As stated in the previous chapter, verifying exact reachability is a hard task.
Here we use two criteria, over-approximation and under-approximation to replace the notion of reachability (shown in Figure \ref{fig:vennDiagram} on page \pageref{fig:vennDiagram}).

%In the context of SLCG, completion is defined as follows: given a state sequence $S$ of observation and a set of possible regulations $H$ (in the form of ABAN) to be verified, find the minimum subset of $H$ such that $S$ is realizable from initial state.

\subsection{Completion by Over-Approximation}
Over-approximation is the reasoning of pseudo-reachability in Definition \ref{defPseudoReach} on page \pageref{defPseudoReach}. 
It associates local states and transitions with the initial state according to the causalities: if there exists a pathway from the target local state to the initial state, this target state can be reachable.
Over-approximation does not take into consideration the order of transitions to be fired, which is the cause of inconclusiveness (literally it over-approximates the reachability).
Thus over-approximation is a necessary condition of the reachability.

Figure \ref{CompOv} gives a first impression of the idea.
The visualization of the set of candidate regulations $R=\{(a,b,+),(c,a,-)\}$ is on the left.
On the right, the initial ABAN has only three variables $\Sigma=\{a,b,c\}$ and initial state $\langle a_0,b_0,c_0\rangle$, with transitions $T=\{\acm{a_1}{b_0}{b_1}\}$.
$b_1$ is not reachable because of the unreachability of $a_1$.
As $(c,a,-)\in R$, \ac{c_0}{a_0}{a_1} is added then $a_1$ becomes reachable which makes $b_1$ also reachable.
$T'=\{\acm{a_1}{b_0}{b_1},\acm{c_0}{a_0}{a_1}\}$, $CS=\{\acm{c_0}{a_0}{a_1}\}$.

\begin{figure}[ht]
\centering
\input{figures/completionOver.tex}
\caption[Completion by over-approximation]{Completion by over-approximation. Dashed arrows represent added action.}\label{CompOv}
\end{figure}
Algorithm \ref{algComOver} in Appendix shows the detailed algorithm.

\subsection{Completion by Under-Approximation}
Over-approximation is only a necessary condition of reachability.
If one wants the guarantee of the reachability even at the price of redundant transitions, he may consider the completion by under-approximation.

Under-approximation is another reasoning of SLCG. 
It associates the local states and the transitions with the initial state and \textit{all the states which may appear}.
This association covers all the orders of occurrence. \textbf{proof here?}
Similar with over-approximation, in the SLCG of under-approximation, if there is a pathway from target local state and the initial state, this target state \textit{should} be reachable.

However, all the orders of occurrence do not necessarily appear during the simulation, which suggest that this approach ``under-approximates'' the reachability.

Additionally, the computation of under-approximation is more complicated than over approximation, as the set of associated local states grows during the computation.
Former added local states need to be regarded as new ``target states''.
This process is called \textit{update}. 
Update does not stop until the set of associated local states becomes stable.


\begin{definition}[Under-approximate SLCG]
Given ABAN $AB = (\Sigma,L,T)$, a global initial state $\alpha$ and a target local state $\omega$, under-approximate SLCG $l= (V_{\mathrm{state}},V_{\mathrm{solution}},E)$ is the smallest recursive structure with $E \subseteq (V_{\mathrm{state}}\times V_{\mathrm{solution}})\cap (V_{\mathrm{solution}}\times V_{\mathrm{state}})$ which satisfies:
\begin{eqnarray*}
    \omega&\in& V_{\mathrm{state}} \\
    a_i\in V_{\mathrm{state}} &\Leftrightarrow& \{ (a_i, sol_{a_i}| head(sol_{a_i})=a_i)\}\subseteq E \\
    sol_{a_i}\in V_{\mathrm{solution}}&\Leftrightarrow& \{ (sol_{a_i},\mathbf{V}(sol_{a_i}))| \mathbf{V}(sol_{a_i})=\varnothing \text{ \rm if } a_i\in \alpha\land a_{1-i}\not\in V_{\mathrm{state}},\\
    &&\text{ \rm else }\mathbf{V}(sol_{a_i})\in body(sol_{a_i}) \}\subseteq E
\end{eqnarray*}
where $V_{\mathrm{state}}\subseteq LS$ is a set of local states, $V_{\mathrm{solution}}\subseteq T$ is the a of solutions and $\mathbf{V}(sol_{a_i})$ is the set of required local states of $sol_{a_i}$. 
\end{definition}

If we compare the definition of under-approximation with Definition \ref{defSLCG} on page \pageref{defSLCG}, the difference lies at the condition of $\mathbf{V}(sol_{a_i})$. 
The reasoning of over-approximation stops when certain automaton $a$ reaches the initial state. 
However, to guarantee all the possible orders, we exige $a_i$ and $a_{1-i}$ are reachable from each other if they are both present in the SLCG.
The corresponding formula is $\mathbf{V}(sol_{a_i})=\varnothing \text{ \rm if } a_i\in \alpha\land a_{1-i}\not\in V_{\mathrm{state}}$.

Let us take the ABAN $AB=(\Sigma, L, T)$ in Figure \ref{ExUnder} as example with $\Sigma= \{a,b,c,d\}$, $T=\{\acm{b_1,c_1}{a_0}{a_1}, \acm{b_1}{d_0}{d_1}, \acm{d_0}{b_0}{b_1}\}$, the initial state $\langle a_0,b_0,c_0,d_0\rangle$.
With candidate regulations $R=\{(d,c,-),(c,d,-)\}$, Figure \ref{Under1}, Figure \ref{Under2} and Figure \ref{Under3} show the procedures of completion by under-approximation: after two additions of actions and one update, the SLCG becomes stable and $a_1$ becomes reachable.
$T'=\{\acm{b_1,c_1}{a_0}{a_1}, \acm{b_1}{d_0}{d_1}, \acm{d_0}{b_0}{b_1},\acm{d_1}{c_0}{c_1}, \acm{c_1}{d_1}{d_0}\}$, $CS=\{\acm{d_1}{c_0}{c_1}, \acm{c_1}{d_1}{d_0}\}$.

The visualization of under-approximate SLCGs has a slight difference with the one of over-approximate SLCGs.
$a_0\Rsh a_1$ means $a_1$ wants to be reached \textit{via} $a_0$.
This notation seems redundant but it is useful when we need to continue the reasoning even we reach the initial state, e.g. in Figure \ref{Under2}, $d_0$ is in the initial state, but the reasoning continues because $d_1$ appears in another branch.

\begin{figure}[ht]
\centering
\input{figures/completionUnder.tex}
\caption[Completion by under-approximation]{Example of completion by under-approximation. Dashed arrows represent added transitions.}\label{ExUnder}
\end{figure}

In Figure \ref{Under1}, \fbox{$c_1$} is unreachable then the joint state $\langle b_1, c_1\rangle$ is not reachable, $a_1$ is not reachable.

\begin{figure}[ht]
\centering
\input{figures/completionUnderLCG1.tex}
\caption[Operations on SLCG(1)]{Step 1, under-approximation S of Figure \ref{ExUnder} studying the reachability of $a_1$ (small circles stand for solutions and squares stand for processes). }\label{Under1}
\end{figure}

In Figure \ref{Under2}, according to candidate regulation ${(d,c,-)}\in R$, transition \ac{d_1}{c_0}{c_1} is added, but the reachability of under-approximation requires all the possible occurrences are realizable, e.g. we need a transition with body $d_0$.

\begin{figure}[ht]
\centering
\input{figures/completionUnderLCG2.tex}
\caption[Operations on SLCG(2)]{Step 2 of completion by under-approximation (filled small circles stand for new possible solutions after completion).}\label{Under2}
\end{figure}

In Figure \ref{Under3}, the completed under-approximate SLCG shows $a_1$ is now reachable after adding $\acm{c_1}{d_1}{d_0}$ according to ${(c,d,-)}\in R$.

\begin{figure}[ht]
\centering
\input{figures/completionUnderLCG3.tex}
\caption[Operations on SLCG(3)]{Step 3 of completion by under-approximation (filled small circles stand for new possible solutions after completion).}\label{Under3}
\end{figure}

Algorithm \ref{algComUnder} in Appendix shows the whole process.

Also, if one wants to study the candidate transitions with multiple variables in the head, he can also replace regulations with transitions, using the same process to complete the ABAN. \textbf{(maybe to be detailed in Appendix?)} 

\section{Model Inference via Statistics}
As we already have the completion methods, to make it applicable, we need to obtain candidate regulations.
Here we introduce a method to generate hypotheses to be verified from time series data.

In the previous contents, only the systems with delay of 1 time unit are discussed (BN, ABAN, etc.), i.e. the influence done by variables will take place at the next time point (immediately).
However, in biological context, some reactions have a long duration, and some even need a whole observation period to take place.
For this reason, we require approaches to reveal transitions of different delays: for an observation of period $T$, possible delays lie in $[1,T-1]$.

\subsection{Preliminaries}
In Definition \ref{def:RN} on page \pageref{def:RN}, the definition of regulatory network (RN) is originally related to a set of approximated ordinary differential equations (ODEs) \cite{khalis2009smbionet}:
%$$\dv{x_v}{t}=k_v+\sum_{u\in v.pred}{x_uk_{uv}s^{\alpha_{uv}}(x_u,\theta_{uv})}-\lambda_v x_v$$
$$\dv{x_v}{t}=k_v-\lambda_v x_v +\sum_{u\in v.pred}{x_uk_{uv}}$$

where $x_v$ is the concentration of variable $v$, $k_v, \lambda_v\in \mathbb{R}$ are self-regulation kinetic parameters and $k_{uv}\in \mathbb{R}$ are kinetic parameters of external regulations.

%\begin{itemize}
%    \item $k_v\in \mathbb{R^{*}}$ and $k_{uv}\in \mathbb{R^{+*}}$ are kinetic parameters
%    \item the function $s^{\alpha_{uv}}$ gives the effect of a regulator $u$ and its target $v$.
%    This function is usually a sigmoid depending on the sign $\alpha_{uv}$ and on the quantitative threshold $\theta_{uv}\in \mathbb{R}^{+*}$ the interaction.
%\end{itemize}

Here, considering the the following reasons, we make several modifications.
\begin{enumerate}
    \item The change rate done by external regulations is not always proportional to the concentration of corresponding external variables. 
    Consider an elementary biochemical reaction $m\mathrm  {A}+n\mathrm  {B}\rightarrow \mathrm  {C}$, according to the rate law, the synthesis rate of C is $r_{\mathrm  {C}}\;=\;k[{\mathrm  {A}}]^{m}[{\mathrm  {B}}]^{n}$ where $k$ is a fixed positive real number.
    \item In the community of model inference, self-regulations are often considered difficult to be detected because nearly every transition could be explained as a self-regulation.
    For example, in DREAM8\footnote{\url{https://www.synapse.org/\#!Synapse:syn1720047/wiki/55342}}, self-regulations are \textit{a priori} ignored.  
    \item The influence is done immediately, without delay.
    Considering the discretization on time, $\delta$ takes only natural numbers in this thesis.
\end{enumerate}

To integrate these hypotheses, the ODEs are modified to:

%$$\dv{x_v}{t}=\sum_{u\in v.pred}{k_{uv}s^{\alpha_{uv}}(x_u,\theta_{uv})}$$
%$$\dv{x_v(t)}{t}=\sum_{u\in v.pred}{x_u(t)k_{uv}}$$
\begin{equation}\label{eq:ode}
    \dv{x_v(t)}{t}=\sum_{u\in v.pred}{x_u^{n}(t-\delta)k_{uv}}
\end{equation}


where $\delta\in \mathbb{R}^{*}$ is the delay of the regulation, $n\in \mathbb{R}^{+}$ is the order of regulation (corresponding to the order of reaction).
Also, self-regulations are not taken into account, i.e. $k_v$ and $\lambda_v$ are set to 0.

The definition of RN requires every regulation take effect immediately.
To cooperate with the new ODEs, it is adapted to the version with delay.

\begin{definition}[Regulatory network with delay]
A regulatory network with delay is a labeled directed graph $G=(V,E)$ where 
\begin{itemize}
    \item each vertex $v$ of $V$, called variable, is provided with a boundary $b_v\in \mathbb{N}$ less or equal to the out-degree of v in G.
    \item each arc $u\in v$ of $E$ is labelled with a triplet ($t_{uv}, \alpha_{uv}, \delta$) where $t_{uv}$ is an integer between 1 and $b_v$, called qualitative threshold, where $\alpha_{uv}\in \{+,-\}$ is the sign of the regulation and $\delta\in \mathbb{N^+}$ is the delay of the regulation.
\end{itemize}
\end{definition}

With the new formalization, we can now address the inference problem.


\subsection{Partial Correlation}

In huge biological networks, it is not possible to compute hypotheses by hand nor to traverse all the possible addable transitions, as stated formerly, the verification of $\mathcal{O}(3^{|Global States|})$ states is a huge task: if the influenced variable is fixed, every other variable has 3 possible influence, promotion, inhibition and no regulation.
 
To deal with the great complexity of verification, \textit{a priori} knowledge is needed. 
Some unsatisfied states can be eliminated without global verification.  
In order to take all the information into account, statistical approaches come into sight.
They try to find relations between different components from the observation of all the time points.

One additional profit of statistical approaches is that original time series data are discretized before being used, which cause a loss of information.
This loss could lead to an imprecise model.
However, some statistical approaches could use directly the continuous time series data as input which avoid this difficulty.

According to Equation \ref{eq:ode} on page \pageref{eq:ode}, for different $n$,
\begin{enumerate}
    \item $n=1$, the change rate of certain variable is the linear sum of other variables.
    The linear correlation between the change rate of one variable and the value of other variables is detectable via an approach using Pearson correlation coefficients (PCC).
    \item $n\neq 1$, the correlations between variables are no longer linear but still monotonous.
    Analogously the \textit{monotonous} correlation is detectable by Spearman correlation coefficients (SCC), which is the application of Pearson correlation coefficients on the rank of variables.
\end{enumerate}

\begin{definition}[Pearson correlation coefficient]
    Pearson correlation coefficient ($r$) is the covariance of the two variables divided by the product of their standard deviations.
    When applied to a sample (time series data), the formula is converted to:
    $${\displaystyle r_{x,y}={\frac {\operatorname {cov} (x,y)}{\sigma _{x}\sigma _{y}}}={\frac {\sum _{i=1}^{n}(x_{i}-{\bar {x}})(y_{i}-{\bar {y}})}{{\sqrt {\sum _{i=1}^{n}(x_{i}-{\bar {x}})^{2}}}{\sqrt {\sum _{i=1}^{n}(y_{i}-{\bar {y}})^{2}}}}}}$$
    Where $x,y$ are variables, $\operatorname {cov} (x,y)$ is the covariance of $x$ and $y$, $\sigma _{x}$ is the standard deviation of $x$, $n$ is the sample size and $x_i,y_i$ are the i-th sample points of $x,y$.
\end{definition}

The definition of Spearman correlation coefficient is related to that of Pearson correlation coefficient.

\begin{definition}[Spearman correlation coefficient]
    Spearman correlation coefficient ($rs$) is the Pearson correlation coefficient between the ranked variables.
    $${\displaystyle rs_{x,y}=r_{\operatorname {rg} _{x},\operatorname {rg} _{y}}={\frac {\operatorname {cov} (\operatorname {rg} _{x},\operatorname {rg} _{y})}{\sigma _{\operatorname {rg} _{x}}\sigma _{\operatorname {rg} _{y}}}}}$$
    Where $rg_x$ is the rank variable of $x$.
\end{definition}

\begin{example}
Variable $x=\{3,10,1,7,6\}$, the rank variable of $x$ is $rg_x=\{4,1,5,2,3\}$.
\end{example}


If two variables are highly correlated and form an independent system, their correlation can be perfectly detected by PCC or SCC.
However, variables are usually simultaneously influenced by more than one variables, which is the biological reality.
For example, for three variables $a,b,c$, if $a$ is activated by $b$ and inhibited by $c$, the PCC or SCC of $r_{\ddv{a}{t},b}$ is biased by $c$. 
To get rid of certain variables, one can apply partial Pearson correlation coefficients \cite{baba2004partial} or partial Spearman correlation coefficients \cite{borror2001practical}.

Partial correlation coefficients are denoted $pr$.

\begin{definition}[Partial Pearson correlation coefficient (PPCC)]
    $pr_{xy\cdot \mathbf {z}}$ is the partial Pearson correlation coefficient of $x$ and $y$ ignoring the influence by $\mathbf {z}$.
    $$pr _{xy\cdot \mathbf {z} }={\frac {pr _{xy\cdot \mathbf {z} \setminus \{z_{0}\}}-pr _{xz_{0}\cdot \mathbf {z} \setminus \{z_{0}\}}pr _{z_{0}y\cdot \mathbf {z} \setminus \{z_{0}\}}}{{\sqrt {1-pr _{xz_{0}\cdot \mathbf {z} \setminus \{z_{0}\}}^{2}}}{\sqrt {1-pr _{z_{0}y\cdot \mathbf {z} \setminus \{z_{0}\}}^{2}}}}}$$
    Where $x,y$ are variables, $\mathbf {z}$ is a set of variables, $z_0$ is an arbitrary element in $z$. 
    Particularly, if $\mathbf {z}$ has only one element $z$, the formula becomes
    $$pr_{x,y\cdot z}={\frac {r _{x,y}-r _{x,z}r _{z,y}}{{\sqrt {1-r _{x,z}^{2}}}{\sqrt {1-r _{z,y}^{2}}}}}$$

\end{definition}

The partial Spearman correlation coefficient is defined likewise.
\begin{definition}[Partial Spearman correlation coefficient (PSCC)]Partial Spearman correlation coefficient is denoted $prs$
    $$prs_{x,y\cdot z}=pr_{rg_x,rg_y\cdot rg_z}$$%={\frac {r _{rg_x,rg_y}-r _{rg_x,rg_z}r _{rg_z,rg_y}}{{\sqrt {1-r _{rg_x,rg_z}^{2}}}{\sqrt {1-r _{rg_z,rg_y}^{2}}}}}$$
\end{definition}

The possible value of all the mentioned correlation coefficients are in the interval $[-1,1]$.
The closer to $1$ the absolute value of the coefficient is, the more correlated the variables are.
Particularly, 1 suggests total positive linear correlation and -1 suggests total negative linear correlation. 
e.g. if we find the PSCC of $\ddv{a}{t}$ and $b$ is -0.9 (high enough), we can add $b\xrightarrow{-}a$ to the set of candidate regulations.

\subsubsection{Overall Process}

With the former definitions, we propose a method applying partial correlation to detect the relevance of each pair of components.

\begin{figure}[ht]
\input{figures/workflowCorrelation.tex}
\caption[Workflow of model inference via partial correlation]{Workflow of the whole procedure of hypotheses generation (dashed arrows stand for optional processes)}\label{plan}
\end{figure}
Figure \ref{plan} shows the procedure of regulation generation: before discretizing original data, Pearson or Spearman correlation coefficient \cite{samaga2009logic,hauke2011comparison} are computed for identifying the relevance between original data and change rates of components (in linear or monotonic way respectively). If cooperation between components exists, former coefficients need replacing by partial ones \cite{de2004discovery} for more precise result.
Resulting coefficients above the threshold (One can set a threshold of correlation, e.g. 0.7) suggest there probably exist regulations between components.

Furthermore, to complete Biological Regulatory Networks in the form of ABAN, more accurate regulations are inferred through variable reconstruction, which splits a variable into several new variable according to its qualitative levels.
For example, variable $a$ has two discrete levels $a_0$ $a_1$, then the correlation coefficients as well as the partial coefficients are computed in the domain of $a_0$ and of $a_1$ separately.
As a result, the correlation between $a_0$ and other components and that of $a_1$ are computed, with which candidate transitions are deduced.

As all the subroutines depicted in Figure \ref{plan} are defined, starting from original data, regulations in form of Thomas' model or ABAN are resulted step by step. In the next, the data treatments Figure \ref{plan} will be introduced with examples.

\subsubsection*{Data Regrouping}
To gain a better understanding of correlations between observation data and change rate, certain observed data of one component are replaced by corresponding change rate. By calculating the correlation coefficients of such matrix, regulation on this component is characterized.

\begin{definition}[Regrouping]
    Let $A$ be a $n\times T$ matrix, representing a time-series data, where $n$ is the number of variables and $T$ the period of the time-series data.
    $A_{ij}$ is the $i$-th variable at time $j$. 
    Let $\delta$ be the delay, there are in total $n$ matrices of size $n\times (T-\delta)$ after regrouping.
    The $k$-th matrix $A^{'k}$ is
    
    \begin{equation}
    \nonumber
    A^{'k}_{ij}=
    \begin{cases}
        \dfrac{A_{i,j+\delta}-A_{ij}}{\delta} & {\rm if\ } i=k\\
         A_{ij} & {\rm if\ } i\neq k
    \end{cases}
\end{equation}
\end{definition}

We group the change rate of one variable and the values of the other variables in order to infer the correlations between them.

Example:

$$\kbordermatrix{\mbox{}&t_0&t_1&t_2&t_3\\
a&a_{t_0}&a_{t_1}&a_{t_2}&a_{t_3}\\
b&b_{t_0}&b_{t_1}&b_{t_2}&b_{t_3}\\
c&c_{t_0}&c_{t_1}&c_{t_2}&c_{t_3}\\
d&d_{t_0}&d_{t_1}&d_{t_2}&d_{t_3}
}
\to\kbordermatrix{\mbox{}&t_0&t_1&t_2\\
a'&a'_{t_0}&a'_{t_1}&a'_{t_2}\\
b&b_{t_0}&b_{t_1}&b_{t_2}\\
c&c_{t_0}&c_{t_1}&c_{t_2}\\
d&d_{t_0}&d_{t_1}&d_{t_2}
}$$

With $ \delta = 1$ time unit, $a'$ is the change rate of $a$, computed via 
\begin{equation}\label{eq:changeRate}
    a'=\dfrac{\Delta a(t)}{\Delta t}=\dfrac{a(t+1)-a(t)}{(t+1)-t}=a(t+1)-a(t)
\end{equation}

In this way, regulations of $b,c,d$ on $a$ are then evaluated by PSCC or PCCC.
Also matrices representing different delays can be formed analogously.

\subsection{Variable Reconstruction}
By following previous steps, regulations in the form of $a\xrightarrow{+/-}b$ are deduced, but the result is not in the precise form of ABAN. 
As is stated on page \ref{par:advantage}, ABAN has a finer description.
We need to study the regulations in different qualitative levels of each variable.
To obtain a result in ABAN form, variable reconstruction is necessary.

\begin{definition}[Variable Reconstruction]
    Let $x(t)$ be a variable in time series data with $l$ levels from $0$ to $l-1$, the corresponding intervals are $[0,x_0],[x_0,x_1],\cdots,[x_{l-2},x_{l-1}]$, with $x_i$ the thresholds. 
    The reconstructed variable of $x$ are:
        $x_i'(t)=x(t)$ with their domain in $\{t|x(t)\in [x_{i-2},x_{i-1}]\}$
\end{definition}

\begin{example}
In Figure \ref{varRec}, with the Boolean discretization, variable $a(t)=0.8\sin t+1\ (t\in [0,7])$ is split into 2 variables $a_0'(t)=0.8\sin t+1\ (t\in (\pi,2\pi))$ (dark gray) and $a_1'(t)=0.8\sin t+1(t\in [0,\pi]\cup[2\pi,7])$ (light gray) with different domains according to the qualitative threshold.
\end{example}

\begin{figure}[ht]
\input{figures/variableReconstrution.tex}
\caption[Variable reconstruction]{Example of variable reconstruction}\label{varRec}
\end{figure}


For the system with 2 Boolean variables $a,b$ split into $a_0,a_1,b_0,b_1$, the PCCC matrix is created as follows:

%Global state after discretization: $L=\{a_0,a_1\}\times \{b_0,b_1\}\ $

Original PCCC Matrix: $r=\left[
\begin{array}{*{20}c}
r_{a'a} & r_{a'b}\\
r_{b'a} & r_{b'b} \\
\end{array}
\right]\ =\left[
\begin{array}{*{20}c}
{\rm N/A} & r_{a'b}\\
r_{b'a} & {\rm N/A} \\
\end{array}
\right]\ 
$

After variable reconstruction:

$$r'=\left[
\begin{array}{*{20}c}
r_{a'_0a_0} & r_{a'_0a_1}& r_{a'_0b_0}&r_{a'_0b_1}\\
r_{a'_1a_0} & r_{a'_1a_1}& r_{a'_1b_0}&r_{a'_1b_1}\\
r_{b'_0a_0} & r_{b'_0a_1}& r_{b'_0b_0}&r_{b'_0b_1}\\
r_{b'_1a_0} & r_{b'_1a_1}& r_{b'_1b_0}&r_{b'_1b_1}\\
\end{array}
\right]\ =\left[\begin{array}{*{20}c}
{\rm N/A} & {\rm N/A}& r_{a'_0b_0}&r_{a'_0b_1}\\
{\rm N/A} & {\rm N/A}& r_{a'_1b_0}&r_{a'_1b_1}\\
r_{b'_0a_0} & r_{b'_0a_1}& {\rm N/A}&{\rm N/A}\\
r_{b'_1a_0} & r_{b'_1a_1}& {\rm N/A}&{\rm N/A}\\
\end{array}\right]$$

Here, even though the size of matrix has doubled (it can also be $n$ times large, depending on discrete levels $n$), as the domains of $a_0,a_1,b_0,b_1$ are not continuous and the variables with same origins (like $a_0$ and $a_1$) have no common domain, hence $r_{a_0a_1}$, $r_{a_1a_0}$, $r_{b_0b_1}$, $r_{b_1b_0}$ are meaningless. 
Also, even some variables of from different origins may have no common domain, that will lead to $r_{a_ib_j}=0$, making resulted matrix more sparse, which gives possibilities of optimization.

\subsection{Toy Example}

To better illustrate the whole process of generating candidate regulations, a toy example of $4$ variables $a$, $b$, $c$ and $d$ is given below.
To prepare the inputs for the model inference in Section \ref{sec:modelInference} on page \pageref{sec:modelInference}, we want to output regulation hypothesis.

Input: time series data in Table \ref{TyTable1}, equi-temporal measurement of 8 time units.

Output: regulation hypotheses for completion of over/under-approximation.

\begin{table}[!ht]
\centering
\begin{tabular}{*{10}{l}}
$t$&0&1&2&3&4&5&6&7&8\\
\hline
$a$&2.01&2.51&1.97&1.17&0.94&0.70&0.31&0.06&0.06\\
$b$&0.74&0.87&0.78&0.33&0.51&0.82&0.86&1.81&1.08\\
$c$&0.43&0.18&0.42&0.23&0.17&0.23&0.32&0.53&0.80\\
$d$&1.62&1.22&1.07&0.57&0.27&0.28&0.24&0.27&0.31
\end{tabular} 
\caption{Original data}\label{TyTable1}
\end{table}



\begin{table}[!ht]
\centering
\begin{tabular}{c*{8}{S}}
$t$&0&1&2&3&4&5&6&7\\
\hline
$a$&0.5&-0.54&-0.8&-0.23&-0.24&-0.39&-0.25&0.0\\
$b$&0.13&-0.09&-0.45&0.18&0.31&0.04&0.95&-0.73\\
$c$&-0.25&0.24&-0.19&-0.06&0.06&0.09&0.21&0.27\\
$d$&-0.4&-0.15&-0.5&-0.3&0.01&-0.04&0.03&0.04
\end{tabular} 
\caption[Change rates]{Change rates derived from original data by $x'[t]=x[t+1]-x[t]$}\label{TyTable2}
\end{table}

Change rates are obtained in Table \ref{TyTable2} by Equation \ref{eq:changeRate}. After data regrouping, we obtain 4 matrices with change rate of  each component respectively, 4 matrices of correlation are then computed: 

$$\kbordermatrix{\mbox{}&a'&b&c&d\\
a'&1.0&0.091&-0.296&-0.090   \\
b&0.091&1.0&-0.738&0.423   \\
c&-0.296&-0.738&1.0&-0.383   \\
d&-0.090&0.423&-0.383&1.0
}
\kbordermatrix{\mbox{}&a&b'&c&d\\
a&1.0&0.653&0.896&-0.976   \\
b'&0.653&1.0&0.747&-0.615   \\
c&0.896&0.747&1.0&-0.883   \\
d&-0.976&-0.615&-0.883&1.0 
}$$
$$\kbordermatrix{\mbox{}&a&b&c'&d\\
a&1.0&0.717&-0.561&-0.929   \\
b&0.717&1.0&-0.709&-0.714   \\
c'&-0.561&-0.709&1.0&0.704   \\
d&-0.929&-0.714&0.704&1.0   
}
\kbordermatrix{\mbox{}&a&b&c&d'\\
a&1.0&-0.678&0.780&0.884   \\
b&-0.678&1.0&-0.929&-0.867   \\
c&0.780&-0.929&1.0&0.907   \\
d'&0.884&-0.867&0.907&1.0   
}$$

 $r'$ is formed by taking the $i$-th line from the $i$-th matrix, which suggests the relevance between change rate of one components and the others.
$$r'=\kbordermatrix{\mbox{}&a&b&c&d\\
a&1.0&0.091&-0.296&-0.0892\\
b&0.652&1.0&0.747&-0.615\\
c&-0.561&-0.709&1.0&0.704\\
d&0.884&-0.867&0.907&1.0
}$$
We can set an arbitrary threshold e.g. 0.6, all the coefficients with their absolute value greater than 0.6 are listed below:
$$(b,a,1,0.652),\ (b,c,1,0.747),\ (b,d,1,-0.615),\ (c,b,1,-0.709)$$
$$(c,d,1,0.704),\ (d,a,1,0.884),\ (d,b,1,-0.867),\ (d,c,1,0.907)$$
For example $(d,b,1,-0.867)$ tells that $d\xrightarrow{-}b$ is probably a good hypothesis as its absolute value of correlation coefficient is close enough to 1. Like this, a BRN model is formed, see Figure \ref{ResultBRN}. According to the configuration of ABAN (whether absence of regulation is regarded as counter regulation), a ABAN is then deduced.

\begin{figure}[ht]
\centering
\input{figures/exampleHypothesis.tex}
\caption{Resulting hypotheses of the toy example}\label{ResultBRN}
\end{figure}

In fact the choice of threshold of correlation coefficients has little influence: if resulting regulations do not satisfy desired properties, we can decrease the threshold down to $0.5$, because when coefficient $r =0.5$, then the $95\%$ prediction interval of $y|x$ will be about 13\% smaller than the $95\%$ prediction interval of $y$, i.e. $y$ behaves more individually than relevantly \cite{hull1927correlation}.

It is worth noticing that the high-correlated variable pairs are not necessarily the reality but can also be a coincidence, i.e. the inferred regulations/transitions can probably reproduce the system dynamics but cannot guarantee the identity.
In fact, there is no method that can guarantee it reveal the reality, as what model inference does is to infer \textit{via} the correlations instead of causality.
Causality, or the reason behind the observation is very hard to retrieve.

\section{Model Revision \textit{via} Reachability Properties and Time-Series Data}
When modeling a real system, instead of causality, one usually require to assess the \textit{consistency} between a given modeling network and the concrete system by checking whether the observed configurations are indeed reachable in the Boolean network.
Whenever it is not the case, it typically means that the designed Boolean functions do not model the given system correctly and thus should be revised before further model analysis.

Inoue \cite{inoue2011logic} has shown that Boolean networks can be represented by logic programs.
In this paper, we provide an approach to revise a logic program to fit temporal properties regarding reachability of partial states.
%
Such logic program can be learned from observations of state transition using LFIT algorithm in \cite{ribeiro2015learning}, but the approach restricts the model to only synchronous update scheme.
One of the benefits of synchronous modeling is computational tractability, while classical state space exploration algorithms fail on asynchronous ones.
Yet the synchronous modeling relies on quite heavy assumptions:
all genes can make a transition simultaneously and need an equivalent amount of time to change their expression level.
Even if this is not realistic from a biological point of view, it is usually sufficient as the exact kinetics and order of transformations are generally unknown.
However, the asynchronous semantics helps one to capture more realistic behaviors \cite{bernot2009}.
At a given time point, at most one single gene can change its expression level.
Non-deterministic behaviors are often observed in biological systems, e.g. cell differentiation.
From a given state, several possible behaviors can be expected as future states.
Asynchronous update scheme results in a potential combinatorial explosion to the number of states.


\subsection{Learning From Interpretation Transitions}\label{sec:lfit}
LFIT framework so far can only capture finite dynamical properties, i.e. relation at $T$-$1$ or $T$-$k$ and the system has to be synchronous deterministic.
In asynchronous systems, non-determinism can lead to loops for several times before taking a path to a certain state.
In this paper, we adapt the algorithms of \cite{ribeiro2015learning,DMTRICLP15} to capture asynchronous dynamics and extend upon this method to propose an approach allowing to fit a logic program to reachability properties.
By modifying rules of the program using logic generalization/specialization operations, we iteratively revise the program to fit a set of reachability/unreachability constraints while keeping the observation and learned rules consistent.

\subsection{Formalization}
    
	Boolean asynchronous systems can be non-deterministic, thus from the same state a variable can take both value $0$ or $1$.
	To encode this dynamics, one requires to have explicit rules for each value of a variable and the modeling of \cite{ribeiro2015learning} is not suitable.
	In \cite{DMTRICLP15}, we proposed a modeling of multi-valued synchronous systems as annotated logic program.
    This modeling can be applied to represent Boolean asynchronous systems and is recalled in the following section.
    %
	In order to represent multi-valued variables, all atoms of a logic program are now restricted to the form $var^{val}$.
	The intuition behind this form is that $var$ represents some variable of the system and $val$ represents the value of this variable.
	In annotated logics, the atom $var$ is said to be annotated by the constant $val$.
	We consider a {\it multi-valued logic program\/} as a set of {\it rules\/} of the form  
	\begin{equation}\label{multi_value}
		var^{val} \leftarrow var_1^{val_1} \wedge \cdots \wedge var_n^{val_n}
	\end{equation}
	where $var^{val}$ and $var_i^{val_i}$ are atoms $(n \geq 1)$.
	For any rule $R$ of the form~(\ref{multi_value}), left part of $\leftarrow$ is called the {\it head\/} of $R$ and is denoted as $h(R)$,
	and the conjunction to the right of $\leftarrow$ is called the {\it body\/} of $R$.  
	We represent the set of literals in the body of $R$ of the form~(\ref{multi_value}) as $b(R)=\{var_1^{val_1},\ldots,var_n^{val_n}\}$. 
	A rule $R$ of the form (\ref{multi_value}) is interpreted as follows:
	the variable $var$ takes the value $val$ in the next state if all variables $var_i$ have the value $val_i$ in the current state.
	A state of a multi-valued program provides the value of each variable of the system and a transitions is a pair of states.
	The value of a variable in a state is called a local state.
	The set of all local state is denoted $\mathbf{LS}$.
	The subset of state is called a partial state.
	A rule $R$ matches a state $s$ when $b(R) \subseteq s$.
	A rule $R$ subsumes a rule $R'$ when $h(R)=h(R'), b(R) \subseteq b(R')$.
%
A Boolean Asynchronous system can be represented by a multi-valued logic program.
This section provides the necessary additional formalization to interpret asynchronous dynamics by such program and to learn from state transitions.

\subsection{Modeling and Learning of Asynchronous Dynamics}\label{sec:alfit}

Due to the non-deterministic nature of asynchronous systems and its restriction to atmost one variable change per transition,
the notion of consistency, realization and successor has to be adapted as follows.

\begin{definition}[Consistency]
	Let $R$ be a rule and $E$ be a set of state transition $(I,J)$.
	$R$ is {\it consistent} with $E$ iff
	$b(R)\subseteq I$ implies $\exists (I,J) \in E, h(R) \in J$.
	A logic program $P$ is {\it consistent} with $E$ if all rules of $P$ are {\it consistent} with $E$.
\end{definition}

\begin{definition}[Program realization]
	Let $P$ be a logic program and $E$ be a set of state transitions.
	$P$ realizes $E$ if $\forall (I,J) \in E, \exists R, b(R) \subseteq I, (I \setminus J) = \{h(R)\}$.
\end{definition}

\begin{definition}[Asynchronous successors]
	Let $I$ be the current state of an asynchronous system represented by a set of multi-valued rules $S$.
	Let $T_P(I,S) = \{h(R) | R \in S, b(R) \subseteq I\}$.
	The successors of $I$ according to $S$ is
	$$T_P^{as}(I,S) = \{I \setminus \{v^{val'}\} \cup \{v^{val}\} | v^{val'} \in I, v^{val} \in T_P(I,S)\} \cup \{I \mid T_P(I,S) = \emptyset\}$$ % Self loop only for non-point atractor
\end{definition}

We now adapt the {\bf LFIT} algorithm of \cite{ribeiro2015learning} to the learning of asynchronous systems.
In synchronous case, the rules $R$ learned by {\bf LFIT} represent a necessity: $h(R)$ \textit{will} be in the next state if $R$ match the current state.
In asynchronous case, the rules represent a possibility: $h(R)$ \textit{can} be in next state if $R$ match the current state.
It allows the modeling of non-determinism: two rules $R, R'$ can have the same head variables but different values and match the same state which occurs in these case:
$h(R)=var^{val}, h(R')=var^{val'}, val \neq val'$ and $var^{val''} \in b(R), var^{val'''}\in b(R') \implies val'' = val'''$.

Like in previous versions, {\bf LFIT} takes a set of state transitions $E$ as input and outputs a logic program $P$ that realizes $E$.
In \cite{DMTRICLP15} multi-valued least specialization was used to learn multi-valued {\bf synchronous} systems dynamics.
Starting from the most general rules, least specialization allows to learn the minimal rules of such system iteratively from its state transition $(I,J) \in E$.
For every possible $var^{val}$, $var^{val} \not \in J$ the most specific rule that is not consistent, with the transition, i.e. an anti-rule, was generated: $MSR := var^{val} \leftarrow I$.
Here, for the {\bf asynchronous} case, this anti-rule is generated and the revision occurs only if $\nexists (I,J') \in E, var^{val'} \in J'$,
i.e. it is impossible to have a transition to $var^{val}$ from $I$.
Each rule of the currently learned program $P$ that subsumes such an anti-rule are specialized using least specialization.
The resulting program $P'$ is consistent and realizes all previously treated transition plus $(I,J)$.
By doing so iteratively for each transition, the algorithm outputs a program $P$ which models the dynamics of the system observed in the transitions $E$.

\vspace{0.5em}
\noindent
\textbf{Asynchronous LFIT}
\vspace{-0.4em}
\begin{itemize}
	\item INPUT: $\mathcal{B}$ a set of annotated atoms and $E$ a set of transitions
	\item Initialize $P := \{var^{val} \leftarrow \emptyset \mid var^{val} \in \mathcal{B}\}$
	\item For each $(I,J) \in E$
	\begin{itemize}
		\item For each $var^{val} \in \mathcal{B}$
		\begin{itemize}
			\item If $\nexists (I,J') \in E, var^{val} \in J'$
			\item $MSR := var^{val} \leftarrow I$
			\item Extract each rule $R$ of $P$ that subsumes $MSR$: $MR := \{R \in P \mid h(R) = var^{val}, b(R) \subseteq I\}, P := P \setminus MR$
			\item For each $R \in MR$
			\begin{itemize}
				\item Compute its least specialization $P'=ls(R,MSR,\mathcal{B})$.
				\item Remove all the rules in $P'$ subsumed by a rule in $P$.
				\item Remove all the rules in $P$ subsumed by a rule in $P'$.
				\item Add all remaining rules in $P'$ to $P$.
			\end{itemize}
		\end{itemize}
	\end{itemize}
	\item OUTPUT: $P$
\end{itemize}

\begin{definition}[Consistent program]
Let $P$ be a logic program, $Re$ (resp. $Un$) be a set of reachability (resp. unreachability) properties.
$P$ is said to be {\em consistent} with $Re$ (resp. $Un$) iff
$\forall (\alpha,\omega) \in Re, \exists$ a trajectory $t$ in $P$ s.t. $\alpha.t=\omega$ and 
$\forall (\alpha,\omega) \in Un, \nexists$ a trajectory $t$ in $P$ s.t. $\alpha.t=\omega$.
\end{definition}

Specializing a rule is to add elements in the body of a rule,
thus to make the condition of a rule more difficult to be satisfied (in a more specialized situation) as the condition of firing becomes more strict.

\begin{definition}[Least specialization of a rule]
	Let $R$ be a rule, a least specialization of $R$ is a rule $R' \in ls(R) := \{h(R) \leftarrow b(R) \cup \{var^{val}\}, \nexists var^{val'} \in b(R)\}$.
	If $R$ contains already all the variables in its body, the only way to specialize $R$ is to remove $R$.
\end{definition}

    Similarly, generalization of a rule is to remove certain elements in the body of a rule, thus to make the condition of a rule easier to be satisfied.

\begin{definition}[Least generalization of a rule]
	Let $R$ be a rule, a least generalization of $R$ is a rule $R' \in lg(R) := \{h(R) \leftarrow b(R) \setminus \{x\},  x \in b(R)\}$.
\end{definition}

\begin{definition}[Revisable]\label{def:revisable}
	A logic program $P$ is said revisable w.r.t. a reachability (resp. unreachability) property if:
	$\exists P' \in \{(P \setminus R_P) \cup \{R' \mid R \in R_P, R' \in ls(R) \cup lg(R)\} \} \mid R_P \subseteq P\}$.
	$P$ is revisable w.r.t. to a set of property $S$:
	if their exists an ordering $S'$ of the elements of $S$ such that each $i$th revision, $0 \leq i \leq |S'|$, ($P$ being the $0$th revision) is revisable w.r.t. the $i+1$th property.
\end{definition} 

From definition \ref{def:revisable}, it follows that the revision of logic program $P$ w.r.t. a set of reachability/unreachability properties $S$ can be found (or proved to be non-existent) by brute force enumeration of all possible ordering of $S$ and trying all possible iterative revisions of $P$.
In the next section we propose an algorithm exploiting the SLCG structure to restrict the search to valid ordering of the properties.
\subsection{Revision}
\label{sec:algorithm}

    In this section we propose an algorithm \textbf{M2RIT} (\textbf{M}odel \textbf{R}evision \textit{via} \textbf{R}eachability and \textbf{I}nterpretation \textbf{T}ransitions) exploiting the previous formalization to fit a logic program to reachability properties.
    Given a set of transition $E$ of an asynchronous system $S$, a logic program $P$ is learned via the adaptation of \textbf{asynchronous LFIT} of section \ref{sec:alfit}.
    When $E$ is partial, the learned program $P$ does not have the exact dynamics of $S$.
    Given a set of reachability properties $Re$ and a set of unreachability properties $Un$ of $S$, we propose an algorithm to revise $P$ so that the dynamics of $P$ satisfy $S$.
    As discussed previously, this can be done by complete brute force but here we propose a first attempt to reduce the search space.
	% TODO: detail why ordering is correct, notion of precedence and so on
    Furthermore, our aim is to find what could be considered a metric of minimal revision of $P$:
    a revision $P'$ s.t. $\nexists P'', (P''\setminus P \cap P'')\subseteq (P' \setminus P \cap P')$
   
    Specialization/generalization operations aim to revise the rule nearest to the target state in the SLCG. If it is not possible, they try to revise the successor, if there is no possible solution, return $\varnothing$ to show the input logic program is not revisable. Specialization operation is limited by the observation. If $P$ after specialization can not explain all the transitions, the specialization is not admissible. %When specializing one rule, we check if all appeared transitions are explained, if not, check if there are other rules can explain it, otherwise we can not specialize it.
    Generalization is similar but without the constraint of the observation, as the observation is partial, $P$ may describe some state transitions never observed.
   
    \noindent
    \begin{minipage}{\linewidth}
    \vspace{1em}
    Specialization:
    \begin{itemize}
        \item \textbf{Input}: a logic program $P$, an unsatisfied element $(\alpha,\omega)$, a reachable set $Re$, an unreachable set $Un$%, a maximum addable components $k$
        \item \textbf{Output}: modified logic program $P$ or $\varnothing$ if not revisable
    \end{itemize}
    \begin{enumerate}
        \item $Rev\gets\{\omega\}$
        \item \textbf{For} each $R$ s.t. $h(R)=Rev$, for each $R'\in\{R''|R''\in ls(R)\land \nexists (I,J)\in E, \text{ s.t. } \nexists R'''\in P\cup \{R''\}\setminus \{R\}, h(R''')\in J, b(R''')\in I\}$
        \begin{itemize}
            \item \textbf{If} $P' \gets P \setminus \{R\} \cup \{R'\}$, $unreachable(P',\alpha,\omega$) and $P'$ satisfies all previous properties, \textbf{return} $P'$
        \end{itemize}
        \item $Rev\gets b(R)$ with $h(R)=Rev$ and back to step 2
        \item There is no revision for $(\alpha,\omega)$, \textbf{return} $\varnothing$
    \end{enumerate}
    \end{minipage}
    \noindent
    \begin{minipage}{\linewidth}
    \vspace{1em}
    Generalization:
    \begin{itemize}
        \item \textbf{Input}: a logic program $P$, an unsatisfied element $(\alpha,\omega)$, a reachable set $Re$, an unreachable set $Un$
        \item \textbf{Output}: modified logic program $P$ or $\varnothing$ if not revisable
    \end{itemize}
    \begin{enumerate}
        \item $Rev\gets\{\omega\}$
        \item \textbf{For} each $R$ s.t. $h(R)=Rev$, for each $R'\in lg(R)$
        \begin{itemize}
            \item \textbf{If} $P' \gets P \setminus \{R\} \cup \{R'\}$, $reachable(P',\alpha,\omega$) and $P'$ satisfies all previous properties, \textbf{return} $P'$
        \end{itemize}
        \item $Rev\gets b(R)$ with $h(R)=Rev$ and back to step 2
        \item There is no revision for $(\alpha,\omega)$, \textbf{return} $\varnothing$
    \end{enumerate}
    \vspace{0.1em}
    \end{minipage}
    \noindent
    \begin{minipage}{\linewidth}
    \vspace{1em}
    Complete revision:
    \begin{itemize}
        \item \textbf{Input}: a logic program $P$, a reachable set $Re$ and an unreachable set $Un$
        \item \textbf{Output}: revised logic program $P$ or $\varnothing$ if not revisable
    \end{itemize}
    \begin{enumerate}
        \item Construct the cycle-free SLCGs for the elements in $Re$ and $Un$ and compute unsatisfied sets $Re'\subseteq Re$ and $Un'\subseteq Un$ which are to be revised
        \item \textbf{If} $Re'=\varnothing$ and $Un'=\varnothing$, \textbf{return} $P$
        \item Let $L=\{l_i,\ldots\}$ with $i\in Re' \cup Un'$, $l_i=\{j,\ldots\}$, with $j=(\alpha,\omega)$, $\omega \in SLCG(i)$ and $ j\in Re\cup Un$ \label{step:dependency}
        \item Pick one of $l_i\in L$ of the smallest cardinality: $\nexists l_i'$, $|l_i'| < |l_i|$ \label{step:cardinality}
        \item \textbf{If} $l_i\cap (Re'\cup Un')\neq\varnothing$, \label{step:check}
        \begin{enumerate}
            \item Reconstruct the SLCG for $i$
            \item \textbf{If} $l_i$ becomes consistent because of former revision, $L\gets L\setminus \{l_i\}$ and back to step 4
        \end{enumerate}
        \item \textbf{If} $i\in Un'$, specialize $P$ to make $i$ unreachable, \textbf{if} not revisable, \textbf{return} $\varnothing$ \label{step:specialize}
        \item Otherwise generalize $P$ to make $i$ reachable, \textbf{if} it is not revisable, \textbf{return} $\varnothing$ \label{step:generalize}
        
        \item $L\gets L\setminus\{l_i\}$ \label{step:update}
        \item \textbf{If} $L\neq\varnothing$ , back to step 1 \label{step:recheck}
        \item \textbf{Return} $P$
    \end{enumerate} 
    \vspace{0.1em}
    \end{minipage}
    
      
    The main algorithm starts with constructing the SLCGs to verify $Re$ and $Un$ in order to ensure the reachability/unreachability properties to be satisfied.
    Then, for the unsatisfied properties, the program $P$ has to be revised.
    SLCG can share the elements s.t. revising one can modify the others.
    By starting with the SLCGs with least dependencies with others, i.e. the ones with the smallest cardinality of $l_i$, it increases the chance of partially satisfying other unsatisfied properties (step \ref{step:dependency} and \ref{step:cardinality}). 
    Then all possible revision of $P$ are generated using least specialization or generalization according to $l_i\in Re$ or $l_i \in Un$ (step \ref{step:specialize} and \ref{step:generalize}). 
    Each revision of $P$ is checked against $Re$ and $Un$ to verify that all properties satisfied by $P$ are still satisfied. 
    If new ones are satisfied, $L$ is updated accordingly (step \ref{step:check}).
    We update $P$ until there is no unsatisfied properties (step \ref{step:update} and \ref{step:recheck}).
    %As the SLCGs are free of cycles, the algorithm always terminates.
    %we revise first the elements whose SLCG contain least other elements in order to modify less $P$.
    Finally, if a revision of $P$ consistent with all given properties is found the algorithm terminates and outputs it.
    
\section{R\'esum\'e}
In this chapter we presented three approaches to infer/revise models based on different \textit{a priori} knowledge.
The first approach allows one to construct a good model among a large number of candidate transitions.
The drawback of the first approach is to obtain the candidates.
To cover this disadvantage, the statistic approach \textit{via} correlation coefficients provides us with candidate regulations to be verified by the first approach.
The statistic approach can use all the continuous time-series data to construct a model from nothing but hard to take into account additional constraints.
The first two approaches are combined as \textbf{CRAC} (\textbf{C}ompletion \textit{via} \textbf{R}eachability \textbf{A}nd \textbf{C}orrelations)

Considering the disadvantages of the combination of CRAC, the third approach \textbf{M2RIT} (Model Revision \textit{via} Reacchability and Interpretation Transitions) does not need candidate transitions and can adjust the result by reachability constraints.
It revises the logic program learned by LFIT w.r.t. the knowledge on reachability properties.
When talking about reachability, we should fix at first update scheme of the dynamic system.
We use asynchronicity as the update scheme as it implies non-determinism which is meaningful to the modeling of nuanced uncertain parts in biology.
From the point of view of revisability, asynchronicity gives the possibilities of modifying the existing transitions.
If the logic program is revisable, the revision is consistent with both state transitions and reachability information.
Intuitively speaking, a given set of time-series data is usually consistent with less synchronous systems than asynchronous systems, thus it is more likely to revise a asynchronous system to satisfy certain reachabilty constraints.

The drawback of M2RIT is that there is a loss of information due to discretization, while the first two approaches make full use of the continuous data.
Moreover, M2RIT does not guarantee the minimal revision of the logic program.

From the contents of this chapter, we propose several topics as future work
\begin{itemize}
    \item Developing heuristics to improve the performance of the existing algorithms
    \item Considering the metric for minimal revision and designing a related algorithm
    \item Reachability in the meaning of continuous models
    \item Adapting more dynamical properties other than reachability
\end{itemize}